{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Wrangling is done for the chennai state of India. size of data: 407,669,106bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason for selecting this part of the map is that I lived major part of my life in this city of Tamil Nadu India --Chennai.\n",
    "The link to this map set https://mapzen.com/data/metro-extracts/metro/chennai_india/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sites that i have been browsing regarding my Data wrangling:stackoverflow,Mongodb.com,http://wiki.openstreetmap.org/wiki/Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing all the packages \n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import json\n",
    "import codecs\n",
    "# storing the path of the osm file in variable name-osm_file\n",
    "osm_file='C:/Users/Praneetha/Documents/chennai_india.osm'\n",
    "SAMPLE_FILE = \"sample.osm\"\n",
    "\n",
    "k = 155 # Parameter: take every k-th top level element\n",
    "# Parsing through the elements of the osm_file\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"\n",
    "    Arguments:(1):Osm_file:the open street map data\n",
    "    (2):elements with tags:node,way and relation \n",
    "    osm_file is iterparsed i.e it is converted into iterable with events start and end\n",
    "    root element is extracted\n",
    "    Parsing through the event and elements and leads to yielding element\n",
    "    Yield is a keyword that is used like return, except the function will return a generator.\n",
    "    (function which can be run only once)\n",
    "    Output is the sample file derieved from the osm_file.the size of the sample file is based\n",
    "    on the value of k.The higher the value of k smaller the size of the sample file.\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(osm_file)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write('</osm>')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the tags in the osm_file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'node': 1}\n",
      "{'node': 11788, 'way': 1}\n",
      "{'node': 11788, 'relation': 1, 'way': 2644}\n"
     ]
    }
   ],
   "source": [
    "def count_tags(SAMPLE_FILE):\n",
    "    \"\"\"\n",
    "    Arguments:sample_file got from the osm_file\n",
    "    this function counts the number of node,way and relation tags present in the sample file\n",
    "    \"\"\"\n",
    "    tags={}\n",
    "    for elem in get_element(SAMPLE_FILE):\n",
    "        if elem.tag in tags :\n",
    "            tags[elem.tag] +=1\n",
    "        else:\n",
    "            tags[elem.tag] =1\n",
    "            elem.clear()\n",
    "            pprint.pprint(tags)\n",
    "count_tags(SAMPLE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the street types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Auditing additional variable i have chosen postal_code\n",
    "postal_code_re=re.compile(r'^\\d{6}$')\n",
    "postal_code=defaultdict(set)\n",
    "def audit_postal_code(postal_code,pcode):\n",
    "    \"\"\"\n",
    "    using regex to fing the postal_code values\n",
    "    if found storing them in code\n",
    "    adding them to defaultdict set postal_code\n",
    "    \"\"\"\n",
    "    m=postal_code_re.search(pcode)\n",
    "    if m:\n",
    "        code=m.group()\n",
    "        postal_code[code].add(pcode)\n",
    "#         print postal_code\n",
    "    return postal_code\n",
    "def is_postal_code(elem):\n",
    "    \"\"\"\n",
    "    checking the key attribute of node tag is postal _code or post_code\n",
    "    \"\"\"\n",
    "    return (elem.attrib['k']==\"postal_code\" or elem.attrib['k']==\"postcode\") \n",
    "# def audit_post(SAMPLE_FILE):\n",
    "#     \"\"\"\n",
    "#     Auditing the postal code where node tags are checked\n",
    "#     iterating through the tag elements \n",
    "#     checking if it is he postal_code or postcode field\n",
    "#     then auditing the value of post code\n",
    "#     postcode references are replaced by postal_code \n",
    "#     \"\"\"\n",
    "#     for elem in get_element(SAMPLE_FILE):\n",
    "#         if elem.tag==\"node\":\n",
    "#             for tag in elem.iter(\"tag\"):\n",
    "#                 if is_postal_code(tag):\n",
    "# #                     if elem.attrib['k']==\"postcode\" :\n",
    "# #                        elem.attrib['k']==\"postal_code\"\n",
    "#                     audit_postal_code(postal_code,tag.attrib['v'])\n",
    "#                     print(postal_code)\n",
    "#     return postal_code \n",
    "# audit_post(SAMPLE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regex expression is used inorder to identify the street types\n",
    "\\b-parses words\n",
    "\\S parses whiteline characters\n",
    "followed by a optional .\n",
    "storing the street types in the default dict of type set inorder to avoid duplicates\n",
    "expected contains the array of street types that can be found in the sample file\n",
    "mapping contains the key value pair where key can be replaced with respective value when found\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "street_types_re=re.compile(r'\\b\\S+\\.?$',re.IGNORECASE)\n",
    "street_types=defaultdict(set)\n",
    "expected=[\"Street\",\"Avenue\",\"Drive\",\"Court\",\"Place\",\"Road\",\"Nagar\",\"Salai\",\"Lane\",\"Highway\",\"South\"]\n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "            \"st\":\"Street\",\n",
    "            \"Ave\":\"Avenue\",\n",
    "            \"Ave.\":\"Avenue\",\n",
    "            \"Rd\":\"Road\",\n",
    "            \"Rd.\":\"Road\",\n",
    "            \"Ln\":\"Lane\",\n",
    "            \"Extn.\":\"Extension\",\n",
    "            \"Extn\":\"Extension\",\n",
    "            \"Col\":\"Colony\",\n",
    "           \"Hwy\":\"Highway\",\n",
    "           \"sou\":\"South\"\n",
    "            }\n",
    "\n",
    "def audit_street_type(street_types,street_name):\n",
    "    \"\"\"\n",
    "    arguments:street_types is the defaultdict(set)\n",
    "    street_name contains the value of the tag attribute passed on from the audit()function\n",
    "    \n",
    "    regex expression is applied on the street_name variable and the street_type is stored.\n",
    "    if the resulting street_type in not found in the expected array ,the value is added to the \n",
    "    defaultdict set(street_types)\n",
    "    \"\"\"\n",
    "    m=street_types_re.search(street_name)\n",
    "    if m:\n",
    "        street_type=m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "            return street_types\n",
    "\n",
    "def is_street_name(elem):\n",
    "    \"\"\"\n",
    "    arguments:the tag elemnt\n",
    "    key value if the tag element is compared to value \"addr:street\" and if it matches it returns True\n",
    "    \"\"\"\n",
    "    return (elem.attrib['k']==\"addr:street\")\n",
    "               \n",
    "def audit(SAMPLE_FILE):\n",
    "    \"\"\"\n",
    "    argument:sample_file\n",
    "    parsing through the elements of the sample_file.\n",
    "    checking the condition if the tag is \"way\"\n",
    "    if true the tag elements are iterated \n",
    "    it is checked whether it is a street by is_street_name() function\n",
    "    then audit_street_type function is called\n",
    "    Returns the street_types of type defaultdict set\n",
    "    \"\"\"\n",
    "    \n",
    "    for elem in get_element(SAMPLE_FILE):\n",
    "        if elem.tag==\"way\":\n",
    "            for tag in elem.iter(\"tag\"): \n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types,tag.attrib['v'])\n",
    "#                     pprint.pprint(dict(street_types))\n",
    "    return street_types\n",
    "# audit(SAMPLE_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems encountered:The street names have to be corrected as not all streets are marked as 'street' few are stated as 'st'.updating similar changes to the dataset is done below:\n",
    "Updating the street names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update_name(name, mapping):\n",
    "  \"\"\"\n",
    "  arguments are passed from the function shape_element()\n",
    "  name is the variable obtained by parsing through street_types which contains all the abbrevated forms\n",
    "  these names are replaced by the values from the mapping array.\n",
    "  the function returns the replaced values from the street_types with the respective mapping values\n",
    "  \"\"\"\n",
    "  m=street_types_re.search(name)\n",
    "  if m:\n",
    "        if m.group() in mapping.keys():\n",
    "           name= re.sub(m.group(),mapping[m.group()],name)\n",
    "  return name\n",
    "# def test():\n",
    "#  st_types=audit(SAMPLE_FILE)\n",
    "#  for st_type,ways in street_types.iteritems():\n",
    "#        for name in ways:\n",
    "#            better_name = update_name(name, mapping)\n",
    "#            print better_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Converting into json format so that it can be imported into MongoDb for further analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "CREATED = {'version': None, 'timestamp': None, 'changeset': None, 'user': None,\n",
    "           'uid': None}\n",
    "def shape_element(element):\n",
    "    \"\"\"\n",
    "    this function updates the street_types with the mapping values by calling the function update_name()\n",
    "    elements are parsed and the values version,timestamp,changeset,user and uid are added to the created array\n",
    "    the latitude and longitude info are added to the pos array.\n",
    "    For further analysis of data ,elements such as amenities,religion,cuisine are analysed\n",
    "    \"\"\"\n",
    "    \n",
    "    node = {}\n",
    "    address = {}\n",
    "    amenity={}\n",
    "    religion={}\n",
    "    cuisine={}\n",
    "    pos = []\n",
    "    st_types=audit(SAMPLE_FILE)\n",
    "    for st_type,ways in street_types.iteritems():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "#         print better_name\n",
    "    for elem in get_element(SAMPLE_FILE):\n",
    "        if elem.tag==\"node\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_postal_code(tag):\n",
    "#                     if elem.attrib['k']==\"postcode\" :\n",
    "#                        elem.attrib['k']==\"postal_code\"\n",
    "                    audit_postal_code(postal_code,tag.attrib['v'])\n",
    "#                     print(postal_code)\n",
    "#                     node[\"postal_code\"]=postal_code\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        node[\"id\"] = element.attrib[\"id\"]\n",
    "        node[\"type\"] =  element.tag\n",
    "        node[ \"visible\"] = element.get(\"visible\")\n",
    "        created = {}\n",
    "        created[\"version\"] = element.attrib[\"version\"]\n",
    "        created[\"changeset\"] = element.attrib[\"changeset\"]\n",
    "        created[\"timestamp\"] = element.attrib[\"timestamp\"]\n",
    "        created[\"user\"] = element.attrib[\"user\"]\n",
    "        node[\"created\"] = created\n",
    "\n",
    "        if \"lat\" in element.keys() and \"lon\" in element.keys():\n",
    "           pos = [element.attrib[\"lat\"], element.attrib[\"lon\"]]\n",
    "           node[\"pos\"] = [float(string) for string in pos]\n",
    "\n",
    "        else:\n",
    "           node[\"pos\"] = None\n",
    "\n",
    "        for tag in element.iter('tag'):\n",
    "           if re.search('amenity',tag.attrib['k']):\n",
    "                a=tag.attrib['k']\n",
    "                amenity[a]=tag.attrib['v']\n",
    "                node['amenity']=amenity\n",
    "           if re.search('religion',tag.attrib['k']):\n",
    "                r=tag.attrib['k']\n",
    "                religion[r]=tag.attrib['v']\n",
    "                node['religion']=religion \n",
    "           if re.search('cuisine',tag.attrib['k']):\n",
    "                c=tag.attrib['k']\n",
    "                cuisine[c]=tag.attrib['v']\n",
    "                node['cuisine']=cuisine     \n",
    "           if re.search('addr:', tag.attrib['k']):\n",
    "                if len(tag.attrib['k'].split(\":\")) < 3:\n",
    "                    addr_add = tag.attrib['k'].split(\":\")[1]\n",
    "                    address[addr_add] = tag.attrib['v']\n",
    "\n",
    "        if address:\n",
    "            node['address'] = address\n",
    "        for nd in element.iter(\"nd\"):\n",
    "            if not \"node_refs\" in node.keys():\n",
    "                node[\"node_refs\"] = []\n",
    "            node_refs = node[\"node_refs\"]\n",
    "            node_refs.append(nd.attrib[\"ref\"])\n",
    "            node[\"node_refs\"] = node_refs\n",
    "        return node\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_map(file_in, pretty = False):\n",
    "    \"\"\"\n",
    "    the function accepts sample file as arguments and returns the respective json file.\n",
    "    \"\"\"\n",
    "    file_out = \"{0}.json\".format(file_in)\n",
    "    data = []\n",
    "    with codecs.open(file_out, \"w\") as fo:\n",
    "        for element in get_element(file_in):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                data.append(el)\n",
    "                if pretty:\n",
    "                    fo.write(json.dumps(el, indent=2)+\"\\n\")\n",
    "                else:\n",
    "                    fo.write(json.dumps(el) + \"\\n\")\n",
    "    return data\n",
    "data = process_map(SAMPLE_FILE, True)\n",
    "# pprint.pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connecting to MongoDB and executing queries based on the imported .json file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_db(db_name):\n",
    "    \"\"\"\n",
    "    Connection with Mongodb is established and the database name is obtained\n",
    "    \"\"\"\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    \"\"\"\n",
    "    The queries are formulated\n",
    "    \"\"\"\n",
    "    pipeline = [{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$sort\":{\"count\":-1}},{\"$limit\":17}]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    \"\"\"\n",
    "    arguments: the database and query\n",
    "    the queries are run on the database\n",
    "    \"\"\"\n",
    "    return [doc for doc in db.osmdata.aggregate(pipeline)]\n",
    "# Top 1 contributing user\n",
    "db = get_db('examples')\n",
    "pipeline = make_pipeline()\n",
    "result = aggregate(db, pipeline)\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Number of users appearing only once (having 1 post)\n",
    "u=db.osmdata.aggregate([{\"$group\":{\"_id\":\"$created.user\", \"count\":{\"$sum\":1}}}, {\"$group\":{\"_id\":\"$count\", \"num_users\":{\"$sum\":1}}}, {\"$sort\":{\"_id\":1}}, {\"$limit\":1}])\n",
    "for doc in u:\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional data exploration using MongoDb queries:\n",
    "Counting the number of nodes and ways using MongoDb:\n",
    "Counting the number of unique users:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Total documents\n",
    "doc_count=db.osmdata.find().count()\n",
    "# node count\n",
    "node_count=db.osmdata.find({\"type\":\"node\"}).count()\n",
    "# unique users\n",
    "unique_user=len(db.osmdata.distinct(\"created.user\"))\n",
    "# way count\n",
    "way_count=db.osmdata.find({\"type\":\"way\"}).count()\n",
    "print node_count\n",
    "print unique_user\n",
    "print way_count\n",
    "print doc_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 10 amenities\n",
    "a=db.osmdata.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}}},\n",
    "                        {\"$group\":{\"_id\":\"$amenity\",\"count\":{\"$sum\":1}}}, \n",
    "                        {\"$sort\":{\"count\":-1}}, {\"$limit\":10}])\n",
    "for doc in a:\n",
    "   print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above results we can see that top amenity is the Place of worship naturally as chennai is called the temple town."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top religion\n",
    "r=db.osmdata.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}}},                                              \n",
    "{\"$group\":{\"_id\":\"$religion\", \"count\":{\"$sum\":1}}},                                                \n",
    "{\"$sort\":{\"count\":-1}}])\n",
    "for doc in r:\n",
    "   print doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the first highest is None we can see that there is some information missing but taking account of other results we can say that Hindu religion is high in number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top cuisine\n",
    "c=db.osmdata.aggregate([{\"$match\":{\"amenity\":{\"$exists\":1}}}, \n",
    "                        {\"$group\":{\"_id\":\"$cuisine\", \"count\":{\"$sum\":1}}}, \n",
    "                        {\"$sort\":{\"count\":-1}}])\n",
    "for doc in c:\n",
    "    print doc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top cuisine of chennai is the Indian cuisine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview of data:\n",
    "More clearity in the data is required as we can see the top count in cuisine and religion is None.Further information provided will give us a clear idea regarding the result.First 10 Top contributing users seems to be very high compared to other users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further Improvements:\n",
    "Naming is not always unambiguous and there are many sources of confusion - from different governmental entities naming the features differently, to inaccurate signposting.\n",
    "OpenStreetMap tries to map reality 'on the ground'.\n",
    "What do the street signs say? What do the local inhabitants call the place?\n",
    "Benefits:\n",
    "I think that local names can also be added to the map would help the tourists and people new to that particular city.\n",
    "Problems:\n",
    "The data may look cluttered on the map.There may be even two to three names for a given place which\n",
    "poses a problem.The pronunciation/spelling should also be considered. Keeping track of all the local names for a place becomes difficult.While auditing data general mapping i.e st-->street becomes difficult in case of local names."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
